{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring a Spark Session\n",
    "1. Initialize application and get a spark session\n",
    "2. This represents your job that runs on a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to read a text file in/using the Session\n",
    "1. You get a property called (read) DataFrameReader\n",
    "2. which has methods to read a variety of files\n",
    "3. text is a method to read text files into a data frame (set of records: rows and columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = spark.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.readwriter.DataFrameReader"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This reads a whole directory\n",
    "dfr.text(r\"C:\\satya\\data\\code\\pyspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we don't want that. So just read ONE Sonnet text file\n",
    "lines=dfr.text(r\"C:\\satya\\data\\code\\pyspark\\sonnet2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|When forty winter...|\n",
      "|And dig deep tren...|\n",
      "|Thy youth's proud...|\n",
      "|Will be a tatter'...|\n",
      "|Then being ask'd ...|\n",
      "|Where all the tre...|\n",
      "|To say, within th...|\n",
      "|Were an all-eatin...|\n",
      "|How much more pra...|\n",
      "|If thou couldst a...|\n",
      "|Shall sum my coun...|\n",
      "|Proving his beaut...|\n",
      "|This were to be n...|\n",
      "|And see thy blood...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore RDD from the DataFrame\n",
    "1. Examine the type of RDD\n",
    "2. directly printing RDD fails as it is distributed on the cluster\n",
    "3. you have to bring the data back to the main node through \"collect\" method\n",
    "4. The collected RDD becomes a plaing python list with rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "asrdd = lines.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(asrdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(value='When forty winters shall beseige thy brow,'), Row(value=\"And dig deep trenches in thy beauty's field,\"), Row(value=\"Thy youth's proud livery, so gazed on now,\"), Row(value=\"Will be a tatter'd weed, of small worth held:\"), Row(value=\"Then being ask'd where all thy beauty lies,\"), Row(value='Where all the treasure of thy lusty days,'), Row(value='To say, within thine own deep-sunken eyes,'), Row(value='Were an all-eating shame and thriftless praise.'), Row(value=\"How much more praise deserved thy beauty's use,\"), Row(value=\"If thou couldst answer 'This fair child of mine\"), Row(value=\"Shall sum my count and make my old excuse,'\"), Row(value='Proving his beauty by succession thine!'), Row(value='This were to be new made when thou art old,'), Row(value=\"And see thy blood warm when thou feel'st it cold.\")]\n"
     ]
    }
   ],
   "source": [
    "print(asrdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddCollected = asrdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(value='When forty winters shall beseige thy brow,'), Row(value=\"And dig deep trenches in thy beauty's field,\"), Row(value=\"Thy youth's proud livery, so gazed on now,\"), Row(value=\"Will be a tatter'd weed, of small worth held:\"), Row(value=\"Then being ask'd where all thy beauty lies,\"), Row(value='Where all the treasure of thy lusty days,'), Row(value='To say, within thine own deep-sunken eyes,'), Row(value='Were an all-eating shame and thriftless praise.'), Row(value=\"How much more praise deserved thy beauty's use,\"), Row(value=\"If thou couldst answer 'This fair child of mine\"), Row(value=\"Shall sum my count and make my old excuse,'\"), Row(value='Proving his beauty by succession thine!'), Row(value='This were to be new made when thou art old,'), Row(value=\"And see thy blood warm when thou feel'st it cold.\")]\n"
     ]
    }
   ],
   "source": [
    "print(rddCollected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapPartitionsRDD[7] at javaToPython at <unknown>:0\n"
     ]
    }
   ],
   "source": [
    "print(asrdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rddCollected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break the lines of the Sonnet into words with map\n",
    "1. See map syntax with a lambda function\n",
    "2. See how the row object is used with indexing and also explicit column name\n",
    "3. Understand the type returened by a map: PipelinedRDD\n",
    "4. Notice this mapped RDD cannot be printed directly unless collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[8] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asrdd.map(lambda row: row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedRDD = asrdd.map(lambda row: row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mappedRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapRDD2 = asrdd.map(lambda row: row.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When forty winters shall beseige thy brow,', \"And dig deep trenches in thy beauty's field,\", \"Thy youth's proud livery, so gazed on now,\", \"Will be a tatter'd weed, of small worth held:\", \"Then being ask'd where all thy beauty lies,\", 'Where all the treasure of thy lusty days,', 'To say, within thine own deep-sunken eyes,', 'Were an all-eating shame and thriftless praise.', \"How much more praise deserved thy beauty's use,\", \"If thou couldst answer 'This fair child of mine\", \"Shall sum my count and make my old excuse,'\", 'Proving his beauty by succession thine!', 'This were to be new made when thou art old,', \"And see thy blood warm when thou feel'st it cold.\"]\n"
     ]
    }
   ],
   "source": [
    "print(mapRDD2.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(value='When forty winters shall beseige thy brow,'), Row(value=\"And dig deep trenches in thy beauty's field,\"), Row(value=\"Thy youth's proud livery, so gazed on now,\"), Row(value=\"Will be a tatter'd weed, of small worth held:\"), Row(value=\"Then being ask'd where all thy beauty lies,\"), Row(value='Where all the treasure of thy lusty days,'), Row(value='To say, within thine own deep-sunken eyes,'), Row(value='Were an all-eating shame and thriftless praise.'), Row(value=\"How much more praise deserved thy beauty's use,\"), Row(value=\"If thou couldst answer 'This fair child of mine\"), Row(value=\"Shall sum my count and make my old excuse,'\"), Row(value='Proving his beauty by succession thine!'), Row(value='This were to be new made when thou art old,'), Row(value=\"And see thy blood warm when thou feel'st it cold.\")]\n"
     ]
    }
   ],
   "source": [
    "print(asrdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore PipelineRDD (output of map)\n",
    "1. Interesting! Read on\n",
    "2. An RDD may contain a collection of any type of objects (may be!)\n",
    "3. The RDD read from a text file definitely has Row/Column types\n",
    "4. However when a map is used, what goes into the PipelineRDD is decided by the map function.\n",
    "5. that is, what ever the map functionr returns. In this case it is a string. You can see that in the following examples\n",
    "6. The collect will merely yield a list of whatever the data type is that is returned by map or what is underneath that RDD, including the PipelineRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mapRDD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstObject = asrdd.first()\n",
    "firstObjectFromMappedRDD = mapRDD2.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.types.Row'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(firstObject))\n",
    "print(type(firstObjectFromMappedRDD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When forty winters shall beseige thy brow,\n"
     ]
    }
   ],
   "source": [
    "print(firstObject.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedRDD = asrdd.map(lambda row: row.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mappedRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[12] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "print(mappedRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When forty winters shall beseige thy brow,', \"And dig deep trenches in thy beauty's field,\", \"Thy youth's proud livery, so gazed on now,\", \"Will be a tatter'd weed, of small worth held:\", \"Then being ask'd where all thy beauty lies,\", 'Where all the treasure of thy lusty days,', 'To say, within thine own deep-sunken eyes,', 'Were an all-eating shame and thriftless praise.', \"How much more praise deserved thy beauty's use,\", \"If thou couldst answer 'This fair child of mine\", \"Shall sum my count and make my old excuse,'\", 'Proving his beauty by succession thine!', 'This were to be new made when thou art old,', \"And see thy blood warm when thou feel'st it cold.\"]\n"
     ]
    }
   ],
   "source": [
    "print(mappedRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedRDDEachLineAList = asrdd.map(lambda row: row.value.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mappedRDDEachLineAList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['When', 'forty', 'winters', 'shall', 'beseige', 'thy', 'brow,'], ['And', 'dig', 'deep', 'trenches', 'in', 'thy', \"beauty's\", 'field,'], ['Thy', \"youth's\", 'proud', 'livery,', 'so', 'gazed', 'on', 'now,'], ['Will', 'be', 'a', \"tatter'd\", 'weed,', 'of', 'small', 'worth', 'held:'], ['Then', 'being', \"ask'd\", 'where', 'all', 'thy', 'beauty', 'lies,'], ['Where', 'all', 'the', 'treasure', 'of', 'thy', 'lusty', 'days,'], ['To', 'say,', 'within', 'thine', 'own', 'deep-sunken', 'eyes,'], ['Were', 'an', 'all-eating', 'shame', 'and', 'thriftless', 'praise.'], ['How', 'much', 'more', 'praise', 'deserved', 'thy', \"beauty's\", 'use,'], ['If', 'thou', 'couldst', 'answer', \"'This\", 'fair', 'child', 'of', 'mine'], ['Shall', 'sum', 'my', 'count', 'and', 'make', 'my', 'old', \"excuse,'\"], ['Proving', 'his', 'beauty', 'by', 'succession', 'thine!'], ['This', 'were', 'to', 'be', 'new', 'made', 'when', 'thou', 'art', 'old,'], ['And', 'see', 'thy', 'blood', 'warm', 'when', 'thou', \"feel'st\", 'it', 'cold.']]\n"
     ]
    }
   ],
   "source": [
    "print(mappedRDDEachLineAList.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "topOfMappedRDD = mappedRDDEachLineAList.top(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(topOfMappedRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Will', 'be', 'a', \"tatter'd\", 'weed,', 'of', 'small', 'worth', 'held:'], ['Where', 'all', 'the', 'treasure', 'of', 'thy', 'lusty', 'days,'], ['When', 'forty', 'winters', 'shall', 'beseige', 'thy', 'brow,'], ['Were', 'an', 'all-eating', 'shame', 'and', 'thriftless', 'praise.'], ['To', 'say,', 'within', 'thine', 'own', 'deep-sunken', 'eyes,'], ['Thy', \"youth's\", 'proud', 'livery,', 'so', 'gazed', 'on', 'now,'], ['This', 'were', 'to', 'be', 'new', 'made', 'when', 'thou', 'art', 'old,'], ['Then', 'being', \"ask'd\", 'where', 'all', 'thy', 'beauty', 'lies,'], ['Shall', 'sum', 'my', 'count', 'and', 'make', 'my', 'old', \"excuse,'\"], ['Proving', 'his', 'beauty', 'by', 'succession', 'thine!']]\n"
     ]
    }
   ],
   "source": [
    "print(topOfMappedRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "topOfRDD = asrdd.top(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(topOfRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(value=\"Will be a tatter'd weed, of small worth held:\"), Row(value='Where all the treasure of thy lusty days,'), Row(value='When forty winters shall beseige thy brow,'), Row(value='Were an all-eating shame and thriftless praise.'), Row(value='To say, within thine own deep-sunken eyes,'), Row(value=\"Thy youth's proud livery, so gazed on now,\"), Row(value='This were to be new made when thou art old,'), Row(value=\"Then being ask'd where all thy beauty lies,\"), Row(value=\"Shall sum my count and make my old excuse,'\"), Row(value='Proving his beauty by succession thine!')]\n"
     ]
    }
   ],
   "source": [
    "print(topOfRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Will be a tatter'd weed, of small worth held:\", 'Where all the treasure of thy lusty days,', 'When forty winters shall beseige thy brow,', 'Were an all-eating shame and thriftless praise.', 'To say, within thine own deep-sunken eyes,', \"Thy youth's proud livery, so gazed on now,\", 'This were to be new made when thou art old,', \"Then being ask'd where all thy beauty lies,\", \"Shall sum my count and make my old excuse,'\", 'Proving his beauty by succession thine!']\n"
     ]
    }
   ],
   "source": [
    "print(mappedRDD.top(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mappedRDD.top(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Frame\n",
    "1. is a collection of Rows\n",
    "2. Each row has a set of columns\n",
    "3. it's underlying RDD can be obtaine through property df.rdd\n",
    "4. lines var below is a DF\n",
    "5. var \"asrdd\" is taken from lines.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "line1 = lines.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.Row"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(line1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(value='When forty winters shall beseige thy brow,')\n"
     ]
    }
   ],
   "source": [
    "print(line1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(asrdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
